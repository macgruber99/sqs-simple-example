# Python Standard Library imports
import json

# third-party library imports
import boto3

from botocore.exceptions import ClientError
from aws_lambda_powertools import Logger

# local imports
from consumer.config import config


def get_ssm_params(path, region_name="us-west-2", recursive=True, with_decryption=True):
    """
    Retrieves all parameters under a given path from AWS SSM Parameter Store.


    :param path (str): The hierarchy for the parameter. Hierarchies start with a forward slash (/).
    :param region_name (str, optional): The AWS region to connect to. Defaults to 'us-west-2'.
    :param recursive (bool, optional): Whether to retrieve parameters recursively under the path. Defaults to True.
    :param with_decryption (bool, optional): Whether to decrypt SecureString parameters. Defaults to True.
    :return (dict): A dictionary where keys are parameter names (relative to the path) and values are parameter values.
    """
    ssm_client = boto3.client("ssm", region_name=region_name)
    parameters = {}
    next_token = None

    while True:
        # Build the request arguments
        kwargs = {
            "Path": path,
            "Recursive": recursive,
            "WithDecryption": with_decryption,
            "MaxResults": 10,  # Can adjust MaxResults as needed, but AWS imposes a limit
        }
        if next_token:
            kwargs["NextToken"] = next_token

        response = ssm_client.get_parameters_by_path(**kwargs)

        # Process the retrieved parameters
        for parameter in response.get("Parameters", []):
            name = parameter["Name"]
            value = parameter["Value"]
            # Remove the path prefix for cleaner parameter names in the result
            if name.startswith(path):
                relative_name = name[len(path) :].lstrip("/")
                parameters[relative_name] = value

        next_token = response.get("NextToken")
        if not next_token:
            break

    if not parameters:
        raise ValueError(f"No parameters found under path '{path}'.")
    else:
        return parameters


def verify_ssm_parameters(params, reqd_params):
    """
    Verify required parameters were retrieved from SSM Parameter Store.

    :param params (dict) The parameters retrieved from SSM Parameter Store.
    :param reqd_params (list) The parameters that are needed for this script to execute.
    :return (None): Default 'None' returned if all required parameters exist.
    """

    for param in reqd_params:
        if param not in params.keys():
            raise ValueError(f"Parameter '{param}' not found.")


def verify_event(event):
    """
    Verify the SQS event has a list of records.

    :param event (dict): A dictionary containing the event.
    :return (None): Default 'None' returned if event has required keys.
    """

    if not (
        isinstance(event, dict)
        and "Records" in event
        and isinstance(event["Records"], list)
    ):
        raise ValueError("Malformed event.")


def verify_sqs_record(record):
    """
    Verify an SQS record has the keys required to process it.

    :param record (dict): The dictionary containing the SQS record.
    :return (None): Default 'None' returned if SQS record has required keys.
    """

    if not (
        isinstance(record, dict)
        and "messageId" in record
        and "body" in record
        and "eventSource" in record
        and "eventSourceARN" in record
    ):
        raise ValueError("Malformed record.")


def verify_sqs_source(record, queue_arn):
    """
    Verify the record was generated by the expected SQS queue.

    :param record (dict): The dictionary containing the SQS record.
    :param queue_arn (str): The ARN of the expected SQS queue.
    :return (None): Default 'None' returned if SQS source is valid.
    """

    if not (
        record["eventSource"] == "aws:sqs" and record["eventSourceARN"] == queue_arn
    ):
        raise ValueError("Invalid SQS source.")


def is_valid_json(json_string):
    """
    Checks if the provided string is a valid JSON.

    :param json_string (str): The string to be validated.
    :return (None): Default 'None' returned if the string is valid JSON.
    """

    json.loads(json_string)


def process_message(msg):
    """
    Processes an SQS message.

    :param msg (str): The body of an SQS message.
    :return (str): The 'text' field of the JSON message.
    """

    json_obj = json.loads(msg)

    if "text" not in json_obj.keys():
        raise KeyError("No text found.")
    else:
        return json_obj["text"]


def check_for_err_str(text):
    """
    Check if text contains the special string that generates an error.

    :param text (str): The text to check.
    :return (None): Default 'None' returned if text does not contain special error string.
    """

    if text == config["special_error_string"]:
        raise ValueError("Found special error string.")


def write_obj_to_s3(bucket_name, file_name, content):
    """
    Writes content to a file in an S3 bucket.

    :param bucket_name (str): The name of the S3 bucket.
    :param file_name (str): The name of the file (object) to create in the bucket.
    :param content (str): The content to write to the file.
    :return (dict): The response data from the S3 API call.
    """

    client = boto3.client("s3")
    resp = client.put_object(Bucket=bucket_name, Key=file_name, Body=content)

    return resp


def lambda_handler(event, context):
    """
    AWS Lambda handler function to send a message to SQS.

    :param event (dict): The event data passed to the Lambda function.
    :param context (dict): The runtime information of the Lambda function.
    :return (dict): The status code and status message.
    """

    # define some variables
    logger = Logger()
    processed_records = 0
    ssm_param_path = config["ssm_param_path"]

    # retrieve SSM Parameter Store parameters under project path
    try:
        ssm_params = get_ssm_params(ssm_param_path)
    except ClientError as e:
        if e.response["Error"]["Code"] == "AccessDeniedException":
            logger.exception(
                f"Lambda function not authorized to get SSM Parameter Store parameters from path '{ssm_param_path}'."
            )
            raise
        else:
            # Handle other ClientErrors
            logger.exception("Error reading parameters from SSM Parameter Store.")
            raise
    except ValueError:
        logger.exception(
            f"No parameters found in SSM Parameter Store under path '{ssm_param_path}'."
        )
        raise
    except Exception:
        logger.exception("Error reading parameters from SSM Parameter Store.")
        raise

    # verify required SSM Parameter Store parameters were retrieved
    try:
        verify_ssm_parameters(ssm_params, config["required_ssm_params"])
        bucket_name = ssm_params["output-bucket-name"]
        queue_arn = ssm_params["queue-arn"]
    except ValueError:
        logger.exception(
            f"Required SSM Parameter Store parameter not found under path '{ssm_param_path}'."
        )
        raise
    except Exception:
        logger.exception(
            "Error occurred while verifying parameters retrieved from SSM Parameter Store."
        )
        raise

    # verify event dict has required keys
    try:
        verify_event(event)
    except ValueError:
        logger.exception(f"SQS event does not contain a list of records: {event}")
        raise
    except Exception:
        logger.exception("Error occurred while verifying the SQS event.")
        raise

    for record in event.get("Records", []):
        logger.info(
            f"Processing {len(event.get('Records', []))} record(s) from the SQS event."
        )

        # verify the SQS record
        try:
            verify_sqs_record(record)
        except ValueError:
            logger.exception(
                f"SQS record does not have required keys to process it: {record}"
            )
            raise
        except Exception:
            logger.exception("Error verifying SQS record.")
            raise

        # verify the event source is the expected SQS queue
        try:
            verify_sqs_source(record, queue_arn)
        except ValueError:
            logger.exception(f"Event not generated from valid SQS source: {record}")
            raise
        except Exception:
            logger.exception("Error occurred while verifying SQS source.")
            raise

        # make sure the body of the SQS record is valid JSON
        try:
            is_valid_json(record["body"])
        except ValueError:
            logger.exception(
                f"Invalid JSON in record with messageId '{record['messageId']}'."
            )
            raise
        except KeyError:
            logger.exception("The SQS record does not contain a 'body' key")
            raise
        except Exception:
            logger.exception("Error validating SQS message body JSON")
            raise

        # process the record
        try:
            logger.info(f"Processing record with messageId '{record['messageId']}'.")
            message = process_message(record["body"])
        except KeyError:
            logger.exception(
                f"Message received from SQS did not contain JSON with 'text' field: {record['body']}"
            )
            raise
        except Exception:
            logger.exception("Error processing record.")
            raise

        try:
            check_for_err_str(message)
        except ValueError:
            logger.exception(
                f"Found special string that generates an error: '{message}'"
            )
            raise

        try:
            logger.info(f"Writing message to S3 bucket '{bucket_name}'.")
            write_obj_to_s3(
                bucket_name,
                f"{record['messageId']}.txt",
                message,
            )
        except ClientError as e:
            if e.response["Error"]["Code"] == "AccessDeniedException":
                logger.exception(
                    f"Lambda function not authorized to write to S3 bucket '{bucket_name}'."
                )
                raise
            else:
                # Handle other ClientErrors
                logger.exception(f"Error writing to S3 bucket '{bucket_name}'.")
                raise
        except Exception:
            logger.exception(f"Error writing to S3 bucket '{bucket_name}'.")
            raise

        processed_records += 1

    logger.info(f"{processed_records} record(s) processed.")
    logger.info("Done.")

    return {
        "statusCode": 200,
        "body": json.dumps("Successfully processed SQS record(s).)"),
    }
